{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMw5/+579b/rIGFWiYCOERH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshSama12/Sinhala-Spell-and-Grammer-Checker/blob/master/sinhala_Spelling_%26GrammerCheck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load Sinhala dataset from Excel file\n",
        "file_path = '/content/data-spell-checker.xlsx'\n",
        "\n",
        "# Read the Excel file into a pandas DataFrame\n",
        "sinhala_data = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "# Check available sheet names\n",
        "print(\"Sheet names:\", sinhala_data.keys())\n",
        "\n",
        "# Assuming the words are in the first sheet, load it\n",
        "sinhala_words_df = pd.read_excel(file_path, sheet_name=0)\n",
        "\n",
        "# Display first few rows\n",
        "print(sinhala_words_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZo19e4ebFL_",
        "outputId": "74f2bec0-eec7-4c74-800c-329f54bfa410"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet names: dict_keys(['Sheet1'])\n",
            "        word  label\n",
            "0  අභිචෝදකයා      1\n",
            "1      අංකනය      1\n",
            "2       අංකන      1\n",
            "3       අංකය      1\n",
            "4  අංකාන්තරය      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all words into a list (assuming the words are in the first column)\n",
        "sinhala_word_list = sinhala_words_df.iloc[:, 0].dropna().tolist()\n",
        "\n",
        "# Convert to a set for quick lookup\n",
        "sinhala_dictionary = set(sinhala_word_list)\n",
        "\n",
        "print(f\"Loaded {len(sinhala_dictionary)} unique Sinhala words.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RID7xTkhbLdf",
        "outputId": "b50d0e05-b9bb-4c74-c048-0f6cf3e831f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 101298 unique Sinhala words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erSKd_EzbWlW",
        "outputId": "0b8d5ff0-c3ed-45be-b646-91decadbc3dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import process\n",
        "\n",
        "# Function to tokenize Sinhala text\n",
        "def tokenize_text(text):\n",
        "    # Match Sinhala words using Unicode range\n",
        "    words = re.findall(r'[\\u0D80-\\u0DFF]+', text)\n",
        "    return words\n",
        "\n",
        "# Function to check for misspellings\n",
        "def check_spelling(tokens, dictionary):\n",
        "    misspelled_words = []\n",
        "    for word in tokens:\n",
        "        if word not in dictionary:\n",
        "            misspelled_words.append(word)\n",
        "    return misspelled_words\n",
        "\n",
        "# Function to suggest corrections\n",
        "def suggest_corrections(word, dictionary, limit=3):\n",
        "    suggestions = process.extract(word, dictionary, limit=limit)\n",
        "    return [match[0] for match in suggestions]\n",
        "\n",
        "# Function to auto-correct text\n",
        "def correct_text(input_text, dictionary):\n",
        "    tokens = tokenize_text(input_text)\n",
        "    corrected_text = input_text\n",
        "    for word in tokens:\n",
        "        if word not in dictionary:\n",
        "            suggestions = suggest_corrections(word, dictionary)\n",
        "            if suggestions:\n",
        "                corrected_word = suggestions[0]\n",
        "                print(f\"Correcting '{word}' to '{corrected_word}'\")\n",
        "                corrected_text = corrected_text.replace(word, corrected_word)\n",
        "    return corrected_text\n",
        "\n",
        "# Example usage\n",
        "input_text = \"අක්ක ඉගෙන ගන්න ගියා.\"  # Example sentence with potential errors\n",
        "print(\"Original Text:\", input_text)\n",
        "\n",
        "corrected_text = correct_text(input_text, sinhala_dictionary)\n",
        "print(\"Corrected Text:\", corrected_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4YX3C0gbQOv",
        "outputId": "599eec6d-0384-4f9b-d63c-ab96c499a919"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: අක්ක ඉගෙන ගන්න ගියා.\n",
            "Correcting 'අක්ක' to 'අක්කාරම්'\n",
            "Correcting 'ඉගෙන' to 'ඉගෙනුම'\n",
            "Correcting 'ගන්න' to 'හරිගස්සගන්න'\n",
            "Corrected Text: අක්කාරම් ඉගෙනුම හරිගස්සගන්න ගියා.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example rule for subject-verb agreement\n",
        "def check_grammar(text):\n",
        "    errors = []\n",
        "    # Rule: Simple example for detecting \"කනවා\" misuse\n",
        "    if re.search(r'කනවා', text):\n",
        "        errors.append(\"Possible verb misuse: 'කනවා' - consider checking context.\")\n",
        "    return errors\n",
        "\n",
        "# Function to correct grammar errors\n",
        "def correct_grammar(text):\n",
        "    corrected_text = text\n",
        "    if 'කනවා' in text:\n",
        "        corrected_text = corrected_text.replace('කනවා', 'කන්නේ')\n",
        "        print(\"Corrected grammar: 'කනවා' to 'කන්නේ'\")\n",
        "    return corrected_text\n",
        "\n",
        "# Example\n",
        "input_text = \"ආනන්ද කනවා\"\n",
        "print(\"Original:\", input_text)\n",
        "\n",
        "grammar_errors = check_grammar(input_text)\n",
        "print(\"Grammar Errors:\", grammar_errors)\n",
        "\n",
        "corrected_text = correct_grammar(input_text)\n",
        "print(\"Corrected Text:\", corrected_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUkmmnUdbrbZ",
        "outputId": "d3c301c4-1163-497e-9849-587e6cc8735a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: ආනන්ද කනවා\n",
            "Grammar Errors: [\"Possible verb misuse: 'කනවා' - consider checking context.\"]\n",
            "Corrected grammar: 'කනවා' to 'කන්නේ'\n",
            "Corrected Text: ආනන්ද කන්නේ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample paragraphs for testing\n",
        "paragraphs = [\n",
        "    \"ආනන්ද කනවා.\",\n",
        "    \"අක්ක ගිහින් ඉගෙන ගන්නවා.\",\n",
        "    \"මම ගෙදර යනවා.\",\n",
        "    \"උදේට බත් කනවා.\",\n",
        "    \"අයියා පාඩම් කරනවා.\"\n",
        "]\n",
        "\n",
        "# Function to evaluate accuracy\n",
        "def evaluate_accuracy(paragraphs, dictionary):\n",
        "    total_words = 0\n",
        "    corrected_words = 0\n",
        "\n",
        "    for text in paragraphs:\n",
        "        tokens = tokenize_text(text)\n",
        "        misspelled_words = check_spelling(tokens, dictionary)\n",
        "        total_words += len(tokens)\n",
        "        corrected_words += len(tokens) - len(misspelled_words)\n",
        "\n",
        "        # Correct grammar and spellings\n",
        "        corrected_text = correct_text(text, dictionary)\n",
        "        corrected_text = correct_grammar(corrected_text)\n",
        "        print(f\"Original: {text}\")\n",
        "        print(f\"Corrected: {corrected_text}\\n\")\n",
        "\n",
        "    accuracy = (corrected_words / total_words) * 100\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on sample paragraphs\n",
        "accuracy = evaluate_accuracy(paragraphs, sinhala_dictionary)\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqTDuKO0buiX",
        "outputId": "b3a5f0a5-4131-4c8b-e3c3-0c345b3a5269"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correcting 'ආනන්ද' to 'ආනන්දය'\n",
            "Corrected grammar: 'කනවා' to 'කන්නේ'\n",
            "Original: ආනන්ද කනවා.\n",
            "Corrected: ආනන්දය කන්නේ.\n",
            "\n",
            "Correcting 'අක්ක' to 'අක්කාරම්'\n",
            "Correcting 'ගිහින්' to 'ගිහි'\n",
            "Correcting 'ඉගෙන' to 'ඉගෙනුම'\n",
            "Original: අක්ක ගිහින් ඉගෙන ගන්නවා.\n",
            "Corrected: අක්කාරම් ගිහි ඉගෙනුම ගන්නවා.\n",
            "\n",
            "Original: මම ගෙදර යනවා.\n",
            "Corrected: මම ගෙදර යනවා.\n",
            "\n",
            "Correcting 'උදේට' to 'ද'\n",
            "Corrected grammar: 'කනවා' to 'කන්නේ'\n",
            "Original: උදේට බත් කනවා.\n",
            "Corrected: ද බත් කන්නේ.\n",
            "\n",
            "Correcting 'අයියා' to 'අය'\n",
            "Correcting 'පාඩම්' to 'පාඩ'\n",
            "Original: අයියා පාඩම් කරනවා.\n",
            "Corrected: අය පාඩ කරනවා.\n",
            "\n",
            "Accuracy: 53.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from rapidfuzz import process\n",
        "\n",
        "# Load Sinhala dataset from Excel file\n",
        "file_path = '/content/data-spell-checker.xlsx'\n",
        "sinhala_words_df = pd.read_excel(file_path, sheet_name=0)\n",
        "\n",
        "# Extract words and convert to a set for fast lookup\n",
        "sinhala_dictionary = set(sinhala_words_df.iloc[:, 0].dropna().tolist())\n",
        "print(f\"Loaded {len(sinhala_dictionary)} Sinhala words.\")\n",
        "\n",
        "# Function to tokenize Sinhala text\n",
        "def tokenize_text(text):\n",
        "    words = re.findall(r'[\\u0D80-\\u0DFF]+', text)\n",
        "    return words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYffrOJrb0Kw",
        "outputId": "f7f14e79-149e-477b-cb11-2c454dde461c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 101298 Sinhala words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check for misspelled words\n",
        "def check_spelling(tokens, dictionary):\n",
        "    misspelled_words = []\n",
        "    for word in tokens:\n",
        "        if word not in dictionary:\n",
        "            misspelled_words.append(word)\n",
        "    return misspelled_words\n",
        "\n",
        "# User input\n",
        "input_text = input(\"Enter a paragraph in Sinhala: \")\n",
        "tokens = tokenize_text(input_text)\n",
        "misspelled = check_spelling(tokens, sinhala_dictionary)\n",
        "\n",
        "print(\"Misspelled words:\", misspelled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPirO8A7dSHa",
        "outputId": "554a01fe-6913-4e93-a0a5-82c9ea75e2e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a paragraph in Sinhala: අක්ක ගිහින් ඉගෙන ගන්නව\n",
            "Misspelled words: ['අක්ක', 'ගිහින්', 'ඉගෙන', 'ගන්නව']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to suggest corrections for a word\n",
        "def suggest_corrections(word, dictionary, limit=5):\n",
        "    suggestions = process.extract(word, dictionary, limit=limit)\n",
        "    return [match[0] for match in suggestions]\n"
      ],
      "metadata": {
        "id": "fzaOChwNdiFS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "# Function to interactively correct text\n",
        "def interactive_correction(input_text, dictionary):\n",
        "    tokens = tokenize_text(input_text)\n",
        "    misspelled = check_spelling(tokens, dictionary)\n",
        "\n",
        "    corrected_text = input_text\n",
        "    queue = deque(misspelled)  # Queue of misspelled words\n",
        "\n",
        "    while queue:\n",
        "        word = queue.popleft()\n",
        "        print(f\"\\nMisspelled Word: {word}\")\n",
        "        suggestions = suggest_corrections(word, dictionary)\n",
        "\n",
        "        print(\"Suggestions:\")\n",
        "        for idx, suggestion in enumerate(suggestions, 1):\n",
        "            print(f\"{idx}. {suggestion}\")\n",
        "\n",
        "        print(\"0. Skip this word\")\n",
        "        choice = int(input(\"Enter the number of the correct word (0 to skip): \"))\n",
        "\n",
        "        if choice > 0 and choice <= len(suggestions):\n",
        "            corrected_word = suggestions[choice - 1]\n",
        "            corrected_text = corrected_text.replace(word, corrected_word, 1)\n",
        "            print(f\"Replaced '{word}' with '{corrected_word}'.\")\n",
        "        else:\n",
        "            print(f\"Skipped correction for '{word}'.\")\n",
        "\n",
        "    return corrected_text\n",
        "\n",
        "# Perform interactive correction\n",
        "corrected_text = interactive_correction(input_text, sinhala_dictionary)\n",
        "print(\"\\nCorrected Text:\")\n",
        "print(corrected_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h325HIVSdlxw",
        "outputId": "d617dc9b-6b73-49f7-ac50-f785f3ec8ebd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misspelled Word: අක්ක\n",
            "Suggestions:\n",
            "1. අක්කාරම්\n",
            "2. අක්කොළ\n",
            "3. අක්කරය\n",
            "4. අක්කොල\n",
            "5. අරක්කු\n",
            "0. Skip this word\n",
            "Enter the number of the correct word (0 to skip): 0\n",
            "Skipped correction for 'අක්ක'.\n",
            "\n",
            "Misspelled Word: ගිහින්\n",
            "Suggestions:\n",
            "1. ගිහි\n",
            "2. හි\n",
            "3. හ\n",
            "4. සිහින්\n",
            "5. ෂිහින්\n",
            "0. Skip this word\n",
            "Enter the number of the correct word (0 to skip): 4\n",
            "Replaced 'ගිහින්' with 'සිහින්'.\n",
            "\n",
            "Misspelled Word: ඉගෙන\n",
            "Suggestions:\n",
            "1. ඉගෙනුම\n",
            "2. ඉගෙනීම\n",
            "3. ඉගිලෙන\n",
            "4. ඉගිළෙන\n",
            "5. සුරැකගෙන\n",
            "0. Skip this word\n",
            "Enter the number of the correct word (0 to skip): 0\n",
            "Skipped correction for 'ඉගෙන'.\n",
            "\n",
            "Misspelled Word: ගන්නව\n",
            "Suggestions:\n",
            "1. ගන්නවා\n",
            "2. බදාගන්නවා\n",
            "3. සාදාගන්නවාට\n",
            "4. සාදාගන්නවා\n",
            "5. සිපගන්නවාට\n",
            "0. Skip this word\n",
            "Enter the number of the correct word (0 to skip): 1\n",
            "Replaced 'ගන්නව' with 'ගන්නවා'.\n",
            "\n",
            "Corrected Text:\n",
            "අක්ක සිහින් ඉගෙන ගන්නවා\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example function to calculate accuracy\n",
        "def calculate_accuracy(corrected_texts, ground_truth_texts):\n",
        "    correct = 0\n",
        "    for corrected, truth in zip(corrected_texts, ground_truth_texts):\n",
        "        if corrected == truth:\n",
        "            correct += 1\n",
        "# Example function to calculate accuracy\n",
        "def calculate_accuracy(corrected_texts, ground_truth_texts):\n",
        "    correct = 0\n",
        "    for corrected, truth in zip(corrected_texts, ground_truth_texts):\n",
        "        if corrected == truth:\n",
        "            correct += 1\n",
        "    return (correct / len(ground_truth_texts)) * 100\n",
        "\n",
        "    print(calculate_accuracy)"
      ],
      "metadata": {
        "id": "-hV-g2_7d4W6"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}