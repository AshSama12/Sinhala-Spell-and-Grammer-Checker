{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshSama12/Sinhala-Spell-and-Grammer-Checker/blob/master/Dl_grammar_checker_with_spell_cheker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YxiBytt8yngg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from difflib import get_close_matches\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl0FxeiX9knV",
        "outputId": "f9c3513b-ec83-4ca0-f57f-df74941e19c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/AI project/correct and wrong sentences .csv'\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and padding setup\n",
        "sentences = df.iloc[:, 0].tolist() + df.iloc[:, 1].tolist() + df.iloc[:, 2].tolist()\n",
        "labels = [0] * len(df.iloc[:, 0]) + [1] * len(df.iloc[:, 1]) + [2] * len(df.iloc[:, 2])\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "_apxcNZ6ubzY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SAcRjCep97va"
      },
      "outputs": [],
      "source": [
        "# One-hot encode labels\n",
        "labels = to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 128\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYiVoTGEuivz",
        "outputId": "b4852acb-d180-44bf-b25f-a2075de1d958"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.3105 - loss: 1.1016 - val_accuracy: 0.3015 - val_loss: 1.0990\n",
            "Epoch 2/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.3792 - loss: 1.0846 - val_accuracy: 0.4570 - val_loss: 1.1187\n",
            "Epoch 3/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6700 - loss: 0.7290 - val_accuracy: 0.6344 - val_loss: 0.7430\n",
            "Epoch 4/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8411 - loss: 0.3937 - val_accuracy: 0.6235 - val_loss: 0.8573\n",
            "Epoch 5/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8776 - loss: 0.3023 - val_accuracy: 0.6112 - val_loss: 1.0169\n",
            "Epoch 6/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8895 - loss: 0.2592 - val_accuracy: 0.5784 - val_loss: 1.2652\n",
            "Epoch 7/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9014 - loss: 0.2341 - val_accuracy: 0.6371 - val_loss: 1.1601\n",
            "Epoch 8/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9271 - loss: 0.1730 - val_accuracy: 0.6535 - val_loss: 1.3399\n",
            "Epoch 9/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9275 - loss: 0.1551 - val_accuracy: 0.6644 - val_loss: 1.4938\n",
            "Epoch 10/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9389 - loss: 0.1301 - val_accuracy: 0.6671 - val_loss: 1.3482\n",
            "Epoch 11/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9526 - loss: 0.1095 - val_accuracy: 0.6658 - val_loss: 1.5120\n",
            "Epoch 12/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9548 - loss: 0.1032 - val_accuracy: 0.6658 - val_loss: 1.6079\n",
            "Epoch 13/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9664 - loss: 0.0784 - val_accuracy: 0.6576 - val_loss: 1.6034\n",
            "Epoch 14/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9657 - loss: 0.0976 - val_accuracy: 0.6630 - val_loss: 1.4262\n",
            "Epoch 15/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.9579 - loss: 0.0926 - val_accuracy: 0.6658 - val_loss: 1.6521\n",
            "Epoch 16/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9722 - loss: 0.0664 - val_accuracy: 0.6453 - val_loss: 1.8995\n",
            "Epoch 17/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9708 - loss: 0.0724 - val_accuracy: 0.6739 - val_loss: 1.5512\n",
            "Epoch 18/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9659 - loss: 0.0938 - val_accuracy: 0.6426 - val_loss: 1.8599\n",
            "Epoch 19/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9771 - loss: 0.0626 - val_accuracy: 0.6835 - val_loss: 1.4902\n",
            "Epoch 20/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9753 - loss: 0.0587 - val_accuracy: 0.6508 - val_loss: 1.7915\n",
            "Epoch 21/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9732 - loss: 0.0601 - val_accuracy: 0.6603 - val_loss: 1.6800\n",
            "Epoch 22/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9773 - loss: 0.0486 - val_accuracy: 0.6548 - val_loss: 1.9981\n",
            "Epoch 23/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9737 - loss: 0.0676 - val_accuracy: 0.6685 - val_loss: 2.0115\n",
            "Epoch 24/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.9776 - loss: 0.0600 - val_accuracy: 0.6862 - val_loss: 1.6672\n",
            "Epoch 25/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9797 - loss: 0.0513 - val_accuracy: 0.6780 - val_loss: 1.8468\n",
            "Epoch 26/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9779 - loss: 0.0560 - val_accuracy: 0.6562 - val_loss: 2.0728\n",
            "Epoch 27/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9768 - loss: 0.0534 - val_accuracy: 0.6821 - val_loss: 1.9083\n",
            "Epoch 28/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9781 - loss: 0.0438 - val_accuracy: 0.6835 - val_loss: 2.0595\n",
            "Epoch 29/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9763 - loss: 0.0508 - val_accuracy: 0.6712 - val_loss: 1.7452\n",
            "Epoch 30/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9828 - loss: 0.0433 - val_accuracy: 0.6685 - val_loss: 2.0049\n",
            "Epoch 31/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9858 - loss: 0.0313 - val_accuracy: 0.6753 - val_loss: 1.9474\n",
            "Epoch 32/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.9786 - loss: 0.0422 - val_accuracy: 0.6889 - val_loss: 2.1597\n",
            "Epoch 33/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9819 - loss: 0.0318 - val_accuracy: 0.6767 - val_loss: 2.2668\n",
            "Epoch 34/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9809 - loss: 0.0343 - val_accuracy: 0.6726 - val_loss: 2.2802\n",
            "Epoch 35/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9703 - loss: 0.0840 - val_accuracy: 0.6644 - val_loss: 1.9909\n",
            "Epoch 36/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9782 - loss: 0.0467 - val_accuracy: 0.6780 - val_loss: 2.0753\n",
            "Epoch 37/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9837 - loss: 0.0381 - val_accuracy: 0.6753 - val_loss: 2.1355\n",
            "Epoch 38/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9809 - loss: 0.0365 - val_accuracy: 0.6739 - val_loss: 2.0694\n",
            "Epoch 39/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9815 - loss: 0.0350 - val_accuracy: 0.6576 - val_loss: 2.1305\n",
            "Epoch 40/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0330 - val_accuracy: 0.6671 - val_loss: 2.3358\n",
            "Epoch 41/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9768 - loss: 0.0615 - val_accuracy: 0.6808 - val_loss: 1.8677\n",
            "Epoch 42/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0408 - val_accuracy: 0.6603 - val_loss: 1.7794\n",
            "Epoch 43/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9784 - loss: 0.0388 - val_accuracy: 0.6794 - val_loss: 1.9137\n",
            "Epoch 44/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9806 - loss: 0.0294 - val_accuracy: 0.6535 - val_loss: 2.1838\n",
            "Epoch 45/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9810 - loss: 0.0325 - val_accuracy: 0.6767 - val_loss: 2.0410\n",
            "Epoch 46/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9841 - loss: 0.0288 - val_accuracy: 0.6821 - val_loss: 1.9487\n",
            "Epoch 47/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.9804 - loss: 0.0299 - val_accuracy: 0.6726 - val_loss: 2.2230\n",
            "Epoch 48/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9837 - loss: 0.0308 - val_accuracy: 0.6698 - val_loss: 2.2443\n",
            "Epoch 49/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.0239 - val_accuracy: 0.6767 - val_loss: 2.2077\n",
            "Epoch 50/50\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9800 - loss: 0.0250 - val_accuracy: 0.6712 - val_loss: 2.1434\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f82e4767130>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model (optional)\n",
        "model.save('/content/drive/MyDrive/AI project/grammar_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJQ76fzt0kNN",
        "outputId": "bd03deba-83e0-43a4-dc13-14036c59f2bf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Sinhala dictionary\n",
        "dictionary_path = '/content/drive/MyDrive/AI project/extended_sinhala_dictionary.txt'\n",
        "with open(dictionary_path, 'r', encoding='utf-8') as file:\n",
        "    sinhala_dictionary = set(file.read().splitlines())\n"
      ],
      "metadata": {
        "id": "PMnwjh4-Rc7X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mRjG-8IA-Ddb"
      },
      "outputs": [],
      "source": [
        "# Spell Checker\n",
        "def sinhala_spell_checker(sentence, dictionary):\n",
        "    words = sentence.split()\n",
        "    corrected_words = []\n",
        "    misspelled_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in dictionary:\n",
        "            corrected_words.append(word)\n",
        "        else:\n",
        "            matches = get_close_matches(word, dictionary, n=3, cutoff=0.8)\n",
        "            if matches:\n",
        "                corrected_words.append(matches[0])\n",
        "                misspelled_words.append((word, matches))\n",
        "            else:\n",
        "                corrected_words.append(word)\n",
        "\n",
        "    return ' '.join(corrected_words), misspelled_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bpWW5yda-U2T"
      },
      "outputs": [],
      "source": [
        "# Sinhala Sentence Tokenizer\n",
        "def sinhala_sent_tokenize(paragraph):\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s', paragraph)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8TexiDhi-gh2"
      },
      "outputs": [],
      "source": [
        "# Grammar Checker\n",
        "def grammar_checker(paragraph, model, tokenizer, max_length):\n",
        "    sentences = sinhala_sent_tokenize(paragraph)\n",
        "    results = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sequence = tokenizer.texts_to_sequences([sentence])\n",
        "        padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
        "        prediction = model.predict(padded_sequence)[0]\n",
        "\n",
        "        if prediction[0] > 0.5:\n",
        "            prediction_label = \"Correct Grammar\"\n",
        "            suggestion = sentence\n",
        "        elif prediction[1] > 0.5:\n",
        "            prediction_label = \"Wrong: Rule 1 Error\"\n",
        "            suggestion = \"Consider revising the verb to match the subject.\"\n",
        "        elif prediction[2] > 0.5:\n",
        "            prediction_label = \"Wrong: Rule 2 Error\"\n",
        "            suggestion = \"Ensure the sentence follows Subject-Object-Verb order.\"\n",
        "        else:\n",
        "            prediction_label = \"Uncertain Error\"\n",
        "            suggestion = \"Review the sentence for possible grammatical mistakes.\"\n",
        "\n",
        "        results.append({\n",
        "            \"sentence\": sentence,\n",
        "            \"prediction\": prediction_label,\n",
        "            \"suggestion\": suggestion\n",
        "        })\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Paragraph\n",
        "def process_paragraph(paragraph, dictionary, model, tokenizer, max_length):\n",
        "    corrected_paragraph, misspelled_words = sinhala_spell_checker(paragraph, dictionary)\n",
        "    grammar_results = grammar_checker(corrected_paragraph, model, tokenizer, max_length)\n",
        "    return corrected_paragraph, misspelled_words, grammar_results\n"
      ],
      "metadata": {
        "id": "jdgUNYFk0Tl-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load model\n",
        "    model = load_model('/content/drive/MyDrive/AI project/grammar_model.h5')\n",
        "\n",
        "    # User input\n",
        "    print(\"Enter a Sinhala paragraph (Press Enter twice to finish):\")\n",
        "    paragraph = \"\"\n",
        "    while True:\n",
        "        line = input()\n",
        "        if line.strip() == \"\":\n",
        "            break\n",
        "        paragraph += \" \" + line\n",
        "\n",
        "    # Process the paragraph\n",
        "    corrected_paragraph, misspelled_words, grammar_results = process_paragraph(\n",
        "        paragraph, sinhala_dictionary, model, tokenizer, max_length\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nMisspelled Words and Suggestions:\")\n",
        "    if not misspelled_words:\n",
        "        print(\"No misspelled words found.\")\n",
        "    else:\n",
        "        for original, suggestions in misspelled_words:\n",
        "            print(f\"Original: {original} | Suggestions: {', '.join(suggestions)}\")\n",
        "\n",
        "    print(\"\\nCorrected Paragraph:\")\n",
        "    print(corrected_paragraph)\n",
        "\n",
        "    print(\"\\nGrammar Results:\")\n",
        "    for result in grammar_results:\n",
        "        print(f\"Sentence: {result['sentence']}\")\n",
        "        print(f\"Prediction: {result['prediction']}\")\n",
        "        print(f\"Suggestion: {result['suggestion']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s8DrZhq0Vf4",
        "outputId": "8fa418dc-e2f2-4b85-bba7-079f286d8ce8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a Sinhala paragraph (Press Enter twice to finish):\n",
            "ඔහුහුවු උදෑසනින්ම පාසල් ගියහ. ඇය ලන්තෑරම රැගෙන පැමිනියාය. ඔහු බෝලයට පයින් ගසයි. අපි සෙමින් ඉදියට ගියෙමු.\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\n",
            "Misspelled Words and Suggestions:\n",
            "Original: බෝලයට | Suggestions: බලයට, බෝගලට\n",
            "Original: ගසයි. | Suggestions: ගයි., රසයි., ගයති.\n",
            "Original: ඉදියට | Suggestions: දියට, ඉදිරියට, දිනයට\n",
            "\n",
            "Corrected Paragraph:\n",
            "ඔහුහුවු උදෑසනින්ම පාසල් ගියහ. ඇය ලන්තෑරම රැගෙන පැමිනියාය. ඔහු බලයට පයින් ගයි. අපි සෙමින් දියට ගියෙමු.\n",
            "\n",
            "Grammar Results:\n",
            "Sentence: ඔහුහුවු උදෑසනින්ම පාසල් ගියහ.\n",
            "Prediction: Correct Grammar\n",
            "Suggestion: ඔහුහුවු උදෑසනින්ම පාසල් ගියහ.\n",
            "Sentence: ඇය ලන්තෑරම රැගෙන පැමිනියාය.\n",
            "Prediction: Correct Grammar\n",
            "Suggestion: ඇය ලන්තෑරම රැගෙන පැමිනියාය.\n",
            "Sentence: ඔහු බලයට පයින් ගයි.\n",
            "Prediction: Correct Grammar\n",
            "Suggestion: ඔහු බලයට පයින් ගයි.\n",
            "Sentence: අපි සෙමින් දියට ගියෙමු.\n",
            "Prediction: Wrong: Rule 2 Error\n",
            "Suggestion: Ensure the sentence follows Subject-Object-Verb order.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDwA5kj_Am39",
        "outputId": "b77d0ee9-4b30-4069-8d07-e1a767fa1f4a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6475 - loss: 2.3420\n",
            "Test Loss: 2.143390417098999\n",
            "Test Accuracy: 0.6712141633033752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVuQMqbsdNE_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1VOrVEgoRQFZbyI7stQy5Vb0J0rjFLdW8",
      "authorship_tag": "ABX9TyNV/iwrdTEMtZvuf9w1j6Hh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}